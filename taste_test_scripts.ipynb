{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Working on modifiying output from SPSS queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import pyreadstat\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_names = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "\n",
    "for variable in variable_names:\n",
    "    frequencies = df[variable].value_counts()\n",
    "    print(f\"Variable: {variable}\")\n",
    "    print(frequencies)\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable value labels for TTQ3 and TTQ4 series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TTQ3.3_1\n",
    "    1\tCitrus, lemon, lime flavor\n",
    "\t2\tFlavor, taste\n",
    "\t3\tTangy, tart\n",
    "\t4\tAftertaste\n",
    "\t5\tFruity flavor\n",
    "\t6\tRefreshing, fresh, light\n",
    "\t7\tLevel of flavor, strong, not too strong, not too weak\n",
    "\t8\tSweetness\n",
    "\t9\tSmooth\n",
    "\t10\tSmell\n",
    "\t97\tNothing\n",
    "\t98\tDon't know\n",
    "\t99\tAll other\n",
    "\n",
    "\n",
    "##### TTQ4.3_1\n",
    "    1\tTart, sour, tang\n",
    "\t2\tLevel of carbonation\n",
    "\t3\tTaste, flavor\n",
    "\t4\tSmell\n",
    "\t5\tAftertaste\n",
    "\t6\tToo strong\n",
    "\t7\tToo weak\n",
    "\t8\tBitter\n",
    "\t9\tColor\n",
    "\t10\tNot sweet enough\n",
    "\t97\tNothing\n",
    "\t98\tDon't know\n",
    "\t99\tAll other\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Q1 = [1, 1, 4, 2, 3]\n",
    "Q2 = [2, 3, 5, 5, 6]\n",
    "Q3 = [1, 2, 7, 2, 6]\n",
    "\n",
    "# Initialize empty dictionaries for frequencies\n",
    "freq_Q1 = {}\n",
    "freq_Q2 = {}\n",
    "freq_Q3 = {}\n",
    "\n",
    "# Count frequencies for Q1\n",
    "for response in Q1:\n",
    "    freq_Q1[response] = freq_Q1.get(response, 0) + 1\n",
    "\n",
    "# Count frequencies for Q2\n",
    "for response in Q2:\n",
    "    freq_Q2[response] = freq_Q2.get(response, 0) + 1\n",
    "\n",
    "# Count frequencies for Q3\n",
    "for response in Q3:\n",
    "    freq_Q3[response] = freq_Q3.get(response, 0) + 1\n",
    "\n",
    "# Combine frequencies into a table\n",
    "table = {\"Q1\": freq_Q1, \"Q2\": freq_Q2, \"Q3\": freq_Q3}\n",
    "\n",
    "# Create a DataFrame from the table\n",
    "df = pd.DataFrame(table)\n",
    "\n",
    "# Transpose the DataFrame\n",
    "df = df.transpose()\n",
    "\n",
    "# Sort columns in ascending order\n",
    "df = df.sort_index(axis=1)\n",
    "\n",
    "# Add a total row\n",
    "df.loc['Total'] = df.sum()\n",
    "\n",
    "# Print the transposed table with total row\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Define the data\n",
    "Q1 = [1, 1, 4, 2, 9]\n",
    "Q2 = [2, 3, 5, 5, 6]\n",
    "Q3 = [1, 2, 7, 2, 6]\n",
    "\n",
    "# Combine the responses into a single list\n",
    "responses = Q1 + Q2 + Q3\n",
    "\n",
    "# Count the frequencies of each response\n",
    "frequency_count = Counter(responses)\n",
    "\n",
    "# Create a table to display the frequencies\n",
    "table_header = [\"Response\", \"Frequency\"]\n",
    "table_rows = []\n",
    "\n",
    "for response, frequency in frequency_count.items():\n",
    "    table_rows.append([response, frequency])\n",
    "\n",
    "# Sort the table rows based on the response values (first column)\n",
    "table_rows.sort(key=lambda x: x[0])\n",
    "\n",
    "# Print the table\n",
    "print(\"-----------------------\")\n",
    "print(\"| {:<10} | {:<8} |\".format(table_header[0], table_header[1]))\n",
    "print(\"-----------------------\")\n",
    "for row in table_rows:\n",
    "    print(\"| {:<10} | {:<8} |\".format(row[0], row[1]))\n",
    "print(\"-----------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = [response for response in df['TTQ3.1_1'] + df['TTQ3.1_2'] + df['TTQ3.1_3'] if response == response]\n",
    "\n",
    "frequency_count = Counter(responses)\n",
    "\n",
    "table_header = ['Response', 'Frequency']\n",
    "table_rows = []\n",
    "\n",
    "for response, frequency in frequency_count.items():\n",
    "    table_rows.append([response, frequency])\n",
    "\n",
    "table_rows.sort(key=lambda x: x[0])\n",
    "\n",
    "# Print the table\n",
    "print(\"-----------------------\")\n",
    "print(\"| {:<10} | {:<8} |\".format(table_header[0], table_header[1]))\n",
    "print(\"-----------------------\")\n",
    "for row in table_rows:\n",
    "    print(\"| {:<10} | {:<8} |\".format(row[0], row[1]))\n",
    "print(\"-----------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TTQ3.1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "# Q1 = [1, 1, 4, 2, 3]\n",
    "# Q2 = [2, 3, 5, 5, 6]\n",
    "# Q3 = [1, 2, 7, 2, 6]\n",
    "\n",
    "# Initialize empty dictionaries for frequencies\n",
    "freq_Q1 = {}\n",
    "freq_Q2 = {}\n",
    "freq_Q3 = {}\n",
    "\n",
    "for response, frequency in df['TTQ3.1_1'].items():\n",
    "    table_rows.append([response, frequency])\n",
    "print(f'response is {response}, frequency is {frequency}')\n",
    "\n",
    "# Count frequencies for Q1\n",
    "for response in df['TTQ3.1_1']:\n",
    "    freq_Q1[response] = freq_Q1.get(response, 0) + 1\n",
    "\n",
    "print(freq_Q1)\n",
    "\n",
    "# Count frequencies for Q2\n",
    "for response in df['TTQ3.1_2']:\n",
    "    freq_Q2[response] = freq_Q2.get(response, 0) + 1\n",
    "\n",
    "# Count frequencies for Q3\n",
    "for response in df['TTQ3.1_3']:\n",
    "    freq_Q3[response] = freq_Q3.get(response, 0) + 1\n",
    "\n",
    "# Combine frequencies into a table\n",
    "table = {\"Q1\": freq_Q1, \"Q2\": freq_Q2, \"Q3\": freq_Q3}\n",
    "\n",
    "# Create a DataFrame from the table\n",
    "df2 = pd.DataFrame(table)\n",
    "\n",
    "print(f'freq_Q1', df2.head())\n",
    "\n",
    "# Transpose the DataFrame\n",
    "df2 = df.transpose()\n",
    "\n",
    "# Sort columns in ascending order\n",
    "df2 = df.sort_index(axis=1)\n",
    "\n",
    "# Add a total row\n",
    "df2.loc['Total'] = df.sum()\n",
    "\n",
    "# Print the transposed table with total row\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_names = ['TTQ3.1_1', 'TTQ3.1_2','TTQ3.1_3']\n",
    "\n",
    "for variable in variable_names:\n",
    "    frequencies = df[variable].value_counts()\n",
    "    print(f\"Variable: {variable}\")\n",
    "    print(frequencies)\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Define the data\n",
    "Q1 = df['TTQ3.1_1']\n",
    "Q2 = df['TTQ3.1_2']\n",
    "Q3 = df['TTQ3.1_3']\n",
    "\n",
    "# Combine the responses into a single list\n",
    "responses = Q1 + Q2 + Q3\n",
    "print(responses)\n",
    "# Count the frequencies of each response\n",
    "frequency_count = Counter(responses)\n",
    "\n",
    "# Create a table to display the frequencies\n",
    "table_header = [\"Response\", \"Frequency\"]\n",
    "table_rows = []\n",
    "\n",
    "for response, frequency in frequency_count.items():\n",
    "    table_rows.append([response, frequency])\n",
    "\n",
    "# Sort the table rows based on the response values (first column)\n",
    "table_rows.sort(key=lambda x: x[0])\n",
    "\n",
    "# Print the table\n",
    "print(\"-----------------------\")\n",
    "print(\"| {:<10} | {:<8} |\".format(table_header[0], table_header[1]))\n",
    "print(\"-----------------------\")\n",
    "for row in table_rows:\n",
    "    print(\"| {:<10} | {:<8} |\".format(row[0], row[1]))\n",
    "print(\"-----------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadstat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "# # Read the SPSS database\n",
    "# data_path = 'path/to/your/database.sav'\n",
    "# df, meta = pyreadstat.read_sav(data_path)\n",
    "\n",
    "# Define the data\n",
    "# Q1 = df['TTQ3.1_1']\n",
    "# Q2 = df['TTQ3.1_2']\n",
    "# Q3 = df['TTQ3.1_3']\n",
    "# Combine two variables into a new variable\n",
    "variable1 = 'TTQ3.1_1'  # Replace with your variable name\n",
    "variable2 = 'TTQ3.1_2'  # Replace with your variable name\n",
    "variable3 = 'TTQ3.1_3'  # Replace with your variable name\n",
    "\n",
    "# new_variable_name = 'CombinedVariable'  # Replace with your desired new variable name\n",
    "\n",
    "new_variable = np.concatenate([df[variable1], df[variable2], df[variable3]])\n",
    "\n",
    "new_variable\n",
    "# Save the modified database\n",
    "# output_path = 'path/to/save/combined_database.sav'  # Replace with your desired output path\n",
    "# pyreadstat.write_sav(df, meta, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# frequencies = df[new_variable].value_counts()\n",
    "frequencies = collections.Counter(new_variable)\n",
    "new_frequencies = frequencies[np.logical_not(pd.isna(frequencies))]\n",
    "# print(f\"Variable: {variable}\")\n",
    "\n",
    "for key, value in new_frequencies.items():\n",
    "    print(f'{key}: {value}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for Taste Test Most/Least slides\n",
    "#### Concat several variables, get frequencies and percentages for the resulting joined variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "# from collections import Counter\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "# Define the data\n",
    "Q1 = df['TTQ3.1_1']\n",
    "Q2 = df['TTQ3.1_2']\n",
    "Q3 = df['TTQ3.1_3']\n",
    "\n",
    "# Combine the responses into a single list\n",
    "responses = pd.concat([Q1, Q2, Q3], axis=0, ignore_index=True).dropna(axis=0)\n",
    "\n",
    "# count responses by variable value\n",
    "value_counts = responses.value_counts().sort_index()\n",
    "# print(value_counts)\n",
    "\n",
    "# Calculate the percentages\n",
    "percentages = (value_counts / value_counts.sum()) * 100\n",
    "\n",
    "# Print the value counts and percentages\n",
    "for value, count in value_counts.items():\n",
    "    percentage = percentages[value]\n",
    "    print(f\"{value}: {count} ({percentage:.0f}%)\")\n",
    "\n",
    "# get total number of counts\n",
    "total_counts = value_counts.sum()\n",
    "print(f'Total counts: {total_counts}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "# from collections import Counter\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "variable_list = ['TTQ3.1_1','TTQ3.1_2','TTQ3.1_3']\n",
    "df_list =()\n",
    "\n",
    "for variable in variable_list:\n",
    "    df_list += f'df[{variable}]'\n",
    "\n",
    "df_list     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "new_list = []\n",
    "\n",
    "for variable in variable_list:\n",
    "    new_list.append(\"df['\" + variable + \"']\")\n",
    "\n",
    "print(new_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "# from collections import Counter\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "variable_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "new_list = []\n",
    "\n",
    "for variable in variable_list:\n",
    "    new_list.append(\"df['\" + variable + \"']\")\n",
    "\n",
    "print(new_list)\n",
    "\n",
    "# Combine the responses into a single list\n",
    "responses = pd.concat([Q1, Q2, Q3], axis=0, ignore_index=True).dropna(axis=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "new_list = []\n",
    "\n",
    "for variable in variable_list:\n",
    "    new_list.append(\"df['\" + variable + \"']\")\n",
    "\n",
    "# Remove double quotes from the strings in new_list\n",
    "new_list = [item.replace(\"\", '') for item in new_list]\n",
    "\n",
    "print(new_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "new_list = []\n",
    "\n",
    "for variable in variable_list:\n",
    "    new_list.append(\"df['\" + variable + \"']\")\n",
    "\n",
    "# Add square brackets to each string in new_list\n",
    "new_list = ['[' + item + ']' for item in new_list]\n",
    "\n",
    "print(new_list)\n",
    "\n",
    "# Combine the responses into a single list\n",
    "responses = pd.concat(new_list, axis=0, ignore_index=True).dropna(axis=0)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatGPT generated code\n",
    "#### Write a python script that automatically generates a sequential variable name and assigns a value to it from a list of provided values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_variable_names(values):\n",
    "    variable_names = []\n",
    "    for i, value in enumerate(values):\n",
    "        variable_name = f'var{i+1}'  # Generate variable name\n",
    "        globals()[variable_name] = value  # Assign value to variable\n",
    "        variable_names.append(variable_name)\n",
    "    return variable_names\n",
    "\n",
    "# Example usage\n",
    "values_list = [10, 20, 30, 40, 50]\n",
    "result = generate_variable_names(values_list)\n",
    "\n",
    "# Print variable names and their corresponding values\n",
    "for variable_name in result:\n",
    "    print(f'{variable_name} = {globals()[variable_name]}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This works but generated var# series is called outside of scope and says not defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "merged_variable = pd.DataFrame()\n",
    "\n",
    "def generate_variable_names(values):\n",
    "    variable_names = []\n",
    "    for i, value in enumerate(values):\n",
    "        variable_name = f'var{i+1}'  # Generate variable name\n",
    "        globals()[variable_name] = value  # Assign value to variable\n",
    "        variable_names.append(variable_name)\n",
    "    return variable_names\n",
    "\n",
    "# Example usage\n",
    "values_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "result = generate_variable_names(values_list)\n",
    "print(f'result = {result}')\n",
    "\n",
    "# Print variable names and their corresponding values\n",
    "for variable_name in result:\n",
    "    print(f'{variable_name} = {globals()[variable_name]}')\n",
    "\n",
    "\n",
    "\n",
    "merged_variable = pd.concat([df[f'{var1}'], df[var2], df[var3]], axis=0, ignore_index=True).dropna(axis=0)\n",
    "print(f'merged_varible = \\n{merged_variable}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "merged_variable = pd.DataFrame()\n",
    "\n",
    "def generate_variable_names(values):\n",
    "    variable_names = []\n",
    "    concated_variables = pd.DataFrame()\n",
    "    for i, value in enumerate(values):\n",
    "        variable_name = f'df[var{i+1}],'  # Generate variable name\n",
    "        globals()[variable_name] = value  # Assign value to variable\n",
    "        variable_names.append(variable_name)\n",
    "        concated_variables = pd.concat([concated_variables, variable_name])\n",
    "    return concated_variables\n",
    "\n",
    "# Example usage\n",
    "values_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "result = generate_variable_names(values_list)\n",
    "print(f'result = {result}')\n",
    "\n",
    "# Print variable names and their corresponding values\n",
    "for variable_name in result:\n",
    "    print(f'{variable_name} = {globals()[variable_name]}')\n",
    "\n",
    "# merged_variable = pd.concat([df[var1], df[var2], df[var3]], axis=0, ignore_index=True).dropna(axis=0)\n",
    "merged_variable = pd.concat([result], axis=0, ignore_index=True).dropna(axis=0)\n",
    "print(merged_variable)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix undefined var# series error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "\n",
    "# Function to read variable list and concatenate all into one dataframe\n",
    "def concat_variables(vars_list):\n",
    "    #create dataframe to store concated values\n",
    "    concated_variable_values = pd.DataFrame()\n",
    "    variable_names = []\n",
    "\n",
    "    for i, value in enumerate(vars_list):\n",
    "        variable_name = f'var{i+1}'  # Generate variable name\n",
    "        globals()[variable_name] = value  # Assign value to variable\n",
    "        variable_names.append(variable_name)\n",
    "        globals()[concated_variable_values] = pd.concat([concated_variable_values, df[value] ])\n",
    "    return concated_variable_values\n",
    "\n",
    "\n",
    "# Example usage\n",
    "variable_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "result = concat_variables(variable_list)\n",
    "print(f'result = {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "# from collections import Counter\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "\n",
    "values_list = [df['TTQ3.1'], df['TTQ3.1_2'], df['TTQ3.1_3']]\n",
    "new_list_df = []\n",
    "\n",
    "for value in values_list:\n",
    "    new_list_df.append(\"df['\" + value + \"']\")\n",
    "\n",
    "print(new_list_df)\n",
    "\n",
    "# get Q# series into var_grouped\n",
    "# for i, value in enumerate(values_list):\n",
    "#     variable_name = f'Q{i+1}'\n",
    "#     print(variable_name)\n",
    "\n",
    "\n",
    "# for i, value in enumerate(vars_list):\n",
    "#         variable_name = f'var{i+1}'  # Generate variable name\n",
    "#         globals()[variable_name] = value  # Assign value to variable\n",
    "#         variable_names.append(variable_name)\n",
    "#         globals()[concated_variable_values] = pd.concat([concated_variable_values, df[value] ])\n",
    "# return concated_variable_values    \n",
    "\n",
    "# var_grouped = [Q1,Q2,Q3]\n",
    "\n",
    "# Combine the responses into a single list\n",
    "# responses = pd.concat(var_grouped, axis=0, ignore_index=True).dropna(axis=0)\n",
    "# print(responses)\n",
    "# # count responses by variable value\n",
    "# # value_counts = responses.value_counts().sort_index()\n",
    "# # print(value_counts)\n",
    "\n",
    "# # Calculate the percentages\n",
    "# # percentages = (value_counts / value_counts.sum()) * 100\n",
    "\n",
    "# # Print the value counts and percentages\n",
    "# for value, count in value_counts.items():\n",
    "#     percentage = percentages[value]\n",
    "#     print(f\"{value}: {count} ({percentage:.0f}%)\")\n",
    "\n",
    "# # get total number of counts\n",
    "# total_counts = value_counts.sum()\n",
    "# print(f'Total counts: {total_counts}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "\n",
    "values_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "values_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "\n",
    "# Initialize an empty dataframe\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over the list of variable names\n",
    "for variable_name in values_list:\n",
    "    # Access the dataframe using globals() and concatenate it to the combined_df\n",
    "    combined_df = pd.concat([combined_df, globals()[variable_name]])\n",
    "\n",
    "# Reset the index of the combined dataframe\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "\n",
    "# Print the combined dataframe\n",
    "print(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['TTQ3.1_1','TTQ3.1_2', 'TTQ3.1_3' ]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "\n",
    "# Read SPSS .sav file\n",
    "# data, meta = pyreadstat.read_sav('input_data.sav')\n",
    "data, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "\n",
    "# List of variable names\n",
    "values_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "\n",
    "# Select variables from the SPSS dataset\n",
    "selected_variables = [variable for variable in meta.column_names if variable in values_list]\n",
    "\n",
    "# Create a new dataframe with selected variables\n",
    "combined_df = data[selected_variables]\n",
    "\n",
    "print(combined_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code reads in the dataframe, and generates the concatenated dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### script produces required data but I want the output to use value labels instead of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "\n",
    "# Read SPSS .sav file\n",
    "data, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "# create a dict so I can use the meta data\n",
    "meta_dict = dict(zip(meta.))\n",
    "\n",
    "# List of variable names\n",
    "values_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "\n",
    "# Select variables from the SPSS dataset\n",
    "selected_variables = [variable for variable in meta.column_names if variable in values_list]\n",
    "\n",
    "# Apply value formats to get meta variable value labels as rows\n",
    "# value_formats = meta.variable_value_labels\n",
    "# combined_df = pd.DataFrame(\n",
    "#     {variable: data[variable].apply(lambda x: value_formats[variable].get(x, x)) for variable in selected_variables,\n",
    "#      axis=0\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# Create a new dataframe by concatenating rows\n",
    "combined_df = pd.concat(\n",
    "    [data[selected_var].rename(selected_var)\n",
    "    for selected_var in selected_variables],\n",
    "    axis=0,\n",
    "    ignore_index=True).dropna(axis=0)\n",
    "# print(combined_df)\n",
    "\n",
    "# count responses by variable value\n",
    "value_counts = responses.value_counts().sort_index()\n",
    "\n",
    "# Calculate the percentages\n",
    "percentages = (value_counts / value_counts.sum()) * 100\n",
    "\n",
    "# Print the value counts and percentages\n",
    "for value, count in value_counts.items():\n",
    "    percentage = percentages[value]\n",
    "    print(f\"{value}: {meta.value.variable_value_labels} {count} ({percentage:.0f}%)\")\n",
    "\n",
    "# get total number of counts\n",
    "total_counts = value_counts.sum()\n",
    "print(f\"Total counts: {total_counts}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the metadata to get variable value labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.variable_value_labels['TTQ3.1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.column_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.value_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.value_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.variable_value_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TTQ3.1_1'].map(meta.variable_value_labels['TTQ3.1_1']).value_counts(normalize=True).loc[meta.variable_value_labels['TTQ3.1_1'].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TTQ3.1_1'].columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting point\n",
    "#### show value labels instead of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aftertaste                                               0.032787\n",
      "All other                                                0.065574\n",
      "Citrus, lemon, lime flavor                               0.049180\n",
      "Flavor, taste                                            0.147541\n",
      "Fruity flavor                                            0.081967\n",
      "Level of flavor, strong, not too strong, not too weak    0.114754\n",
      "Nothing                                                  0.229508\n",
      "Refreshing                                               0.131148\n",
      "Smooth                                                   0.049180\n",
      "Sweetness                                                0.081967\n",
      "Tangy                                                    0.016393\n",
      "Name: proportion, dtype: float64\n",
      "Total counts: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "\n",
    "# Read SPSS .sav file\n",
    "data, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "df_copy = pyreadstat.set_value_labels(data, meta)\n",
    "\n",
    "# List of variable names\n",
    "values_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "\n",
    "# Select variables from the SPSS dataset\n",
    "selected_variables = [variable for variable in meta.column_names if variable in values_list]\n",
    "\n",
    "# Create a new dataframe by concatenating rows\n",
    "combined_df = pd.concat(\n",
    "    [df_copy[selected_var].rename(selected_var)\n",
    "    for selected_var in selected_variables],\n",
    "    axis=0,\n",
    "    ignore_index=True).dropna(axis=0)\n",
    "# print(combined_df)\n",
    "\n",
    "# Apply value formats to get meta variable value labels as rows\n",
    "# value_formats = meta.variable_value_labels\n",
    "# combined_df = pd.DataFrame({\n",
    "#     variable: df_copy[variable].apply(lambda x: value_formats[variable].get(x, x)) for variable in selected_variables}\n",
    "# )\n",
    "\n",
    "# count responses by variable value\n",
    "# value_counts = responses.value_counts().sort_index()\n",
    "value_counts = combined_df.value_counts(normalize=True).sort_index()\n",
    "print(value_counts)\n",
    "\n",
    "# Calculate the percentages\n",
    "# percentages = (value_counts / value_counts.sum()) * 100\n",
    "\n",
    "# Print the value counts and percentages\n",
    "# for value, count in value_counts.items():\n",
    "# for value, count in combined_df.items():\n",
    "    # percentage = percentages[value]\n",
    "    # print(f\"{value}: {count} ({percentages[value]:.0f}%)\")\n",
    "    # print(f\"{value}: {count}\")\n",
    "\n",
    "# get total number of counts\n",
    "total_counts = value_counts.sum()\n",
    "print(f\"Total counts: {total_counts}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aftertaste                                               0.032787\n",
      "All other                                                0.065574\n",
      "Citrus, lemon, lime flavor                               0.049180\n",
      "Flavor, taste                                            0.147541\n",
      "Fruity flavor                                            0.081967\n",
      "Level of flavor, strong, not too strong, not too weak    0.114754\n",
      "Nothing                                                  0.229508\n",
      "Refreshing                                               0.131148\n",
      "Smooth                                                   0.049180\n",
      "Sweetness                                                0.081967\n",
      "Tangy                                                    0.016393\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "value_counts = combined_df.value_counts(normalize=True).sort_index()\n",
    "print(value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m value\n",
      "\u001b[0;31mNameError\u001b[0m: name 'value' is not defined"
     ]
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 284 is out of bounds for axis 0 with size 11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(percentages[value]\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1004\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1001\u001b[0m     key \u001b[39m=\u001b[39m unpack_1tuple(key)\n\u001b[1;32m   1003\u001b[0m \u001b[39mif\u001b[39;00m is_integer(key) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_should_fallback_to_positional:\n\u001b[0;32m-> 1004\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m   1007\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_value(key)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 284 is out of bounds for axis 0 with size 11"
     ]
    }
   ],
   "source": [
    "print(percentages[value].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "\n",
    "# Read SPSS .sav file\n",
    "data, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "# List of variable names\n",
    "values_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "\n",
    "# Select variables from the SPSS dataset\n",
    "selected_variables = [variable for variable in meta.column_names if variable in values_list]\n",
    "\n",
    "# Create dict for meta data\n",
    "meta_dict = dict(zip(meta.column_names, meta.column_labels))\n",
    "\n",
    "# Create a new dataframe by concatenating rows\n",
    "combined_df = pd.concat(\n",
    "    [data[selected_var].rename(selected_var)\n",
    "    for selected_var in selected_variables],\n",
    "    axis=0,\n",
    "    ignore_index=True).dropna(axis=0)\n",
    "# print(combined_df)\n",
    "\n",
    "# Apply value formats to get meta variable value labels as rows\n",
    "value_formats = meta.variable_value_labels\n",
    "combined_df = pd.DataFrame({\n",
    "    variable: data[variable].apply(lambda x: value_formats[values_list].get(x, x)) for variable in selected_variables}\n",
    ")\n",
    "\n",
    "# count responses by variable value\n",
    "value_counts = responses.value_counts().sort_index()\n",
    "# This should work but may need to loop through 'responses' one at a time to get map to work corrrectly\n",
    "value_counts = responses.map(meta.variable_value_labels[responses]).value_counts(normalize=True).sort_index()\n",
    "\n",
    "\n",
    "# Calculate the percentages\n",
    "# percentages = (value_counts / value_counts.sum()) * 100\n",
    "\n",
    "# Print the value counts and percentages\n",
    "for value, count in value_counts.items():\n",
    "    percentage = percentages[value]\n",
    "    print(f\"{value}: {count} ({percentage:.0f}%)\")\n",
    "\n",
    "# get total number of counts\n",
    "total_counts = value_counts.sum()\n",
    "print(f\"Total counts: {total_counts}\")\n",
    "\n",
    "df['TTQ3.1_1'].value_counts(normalize=True)\n",
    "df['TTQ3.1_1'].map(meta.variable_value_labels['TTQ3.1_1']).value_counts(normalize=True).sort_index()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
