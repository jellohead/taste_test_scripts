{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Working on modifiying output from SPSS queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import pyreadstat\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: TTQ3.1_1\n",
      "97.0    14\n",
      "2.0      8\n",
      "7.0      7\n",
      "6.0      5\n",
      "8.0      4\n",
      "5.0      4\n",
      "99.0     4\n",
      "1.0      3\n",
      "9.0      3\n",
      "4.0      2\n",
      "3.0      1\n",
      "Name: TTQ3.1_1, dtype: int64\n",
      "-------------------\n",
      "Variable: TTQ3.1_2\n",
      "6.0    3\n",
      "2.0    1\n",
      "8.0    1\n",
      "5.0    1\n",
      "Name: TTQ3.1_2, dtype: int64\n",
      "-------------------\n",
      "Variable: TTQ3.1_3\n",
      "Series([], Name: TTQ3.1_3, dtype: int64)\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "variable_names = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "\n",
    "for variable in variable_names:\n",
    "    frequencies = df[variable].value_counts()\n",
    "    print(f\"Variable: {variable}\")\n",
    "    print(frequencies)\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable value labels for TTQ3 and TTQ4 series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TTQ3.3_1\n",
    "    1\tCitrus, lemon, lime flavor\n",
    "\t2\tFlavor, taste\n",
    "\t3\tTangy, tart\n",
    "\t4\tAftertaste\n",
    "\t5\tFruity flavor\n",
    "\t6\tRefreshing, fresh, light\n",
    "\t7\tLevel of flavor, strong, not too strong, not too weak\n",
    "\t8\tSweetness\n",
    "\t9\tSmooth\n",
    "\t10\tSmell\n",
    "\t97\tNothing\n",
    "\t98\tDon't know\n",
    "\t99\tAll other\n",
    "\n",
    "\n",
    "##### TTQ4.3_1\n",
    "    1\tTart, sour, tang\n",
    "\t2\tLevel of carbonation\n",
    "\t3\tTaste, flavor\n",
    "\t4\tSmell\n",
    "\t5\tAftertaste\n",
    "\t6\tToo strong\n",
    "\t7\tToo weak\n",
    "\t8\tBitter\n",
    "\t9\tColor\n",
    "\t10\tNot sweet enough\n",
    "\t97\tNothing\n",
    "\t98\tDon't know\n",
    "\t99\tAll other\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1    2    3    4    5    6    7\n",
      "Q1     2.0  1.0  1.0  1.0  NaN  NaN  NaN\n",
      "Q2     NaN  1.0  1.0  NaN  2.0  1.0  NaN\n",
      "Q3     1.0  2.0  NaN  NaN  NaN  1.0  1.0\n",
      "Total  3.0  4.0  2.0  1.0  2.0  2.0  1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Q1 = [1, 1, 4, 2, 3]\n",
    "Q2 = [2, 3, 5, 5, 6]\n",
    "Q3 = [1, 2, 7, 2, 6]\n",
    "\n",
    "# Initialize empty dictionaries for frequencies\n",
    "freq_Q1 = {}\n",
    "freq_Q2 = {}\n",
    "freq_Q3 = {}\n",
    "\n",
    "# Count frequencies for Q1\n",
    "for response in Q1:\n",
    "    freq_Q1[response] = freq_Q1.get(response, 0) + 1\n",
    "\n",
    "# Count frequencies for Q2\n",
    "for response in Q2:\n",
    "    freq_Q2[response] = freq_Q2.get(response, 0) + 1\n",
    "\n",
    "# Count frequencies for Q3\n",
    "for response in Q3:\n",
    "    freq_Q3[response] = freq_Q3.get(response, 0) + 1\n",
    "\n",
    "# Combine frequencies into a table\n",
    "table = {\"Q1\": freq_Q1, \"Q2\": freq_Q2, \"Q3\": freq_Q3}\n",
    "\n",
    "# Create a DataFrame from the table\n",
    "df = pd.DataFrame(table)\n",
    "\n",
    "# Transpose the DataFrame\n",
    "df = df.transpose()\n",
    "\n",
    "# Sort columns in ascending order\n",
    "df = df.sort_index(axis=1)\n",
    "\n",
    "# Add a total row\n",
    "df.loc['Total'] = df.sum()\n",
    "\n",
    "# Print the transposed table with total row\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "| Response   | Frequency |\n",
      "-----------------------\n",
      "| 1          | 3        |\n",
      "| 2          | 4        |\n",
      "| 3          | 1        |\n",
      "| 4          | 1        |\n",
      "| 5          | 2        |\n",
      "| 6          | 2        |\n",
      "| 7          | 1        |\n",
      "| 9          | 1        |\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Define the data\n",
    "Q1 = [1, 1, 4, 2, 9]\n",
    "Q2 = [2, 3, 5, 5, 6]\n",
    "Q3 = [1, 2, 7, 2, 6]\n",
    "\n",
    "# Combine the responses into a single list\n",
    "responses = Q1 + Q2 + Q3\n",
    "\n",
    "# Count the frequencies of each response\n",
    "frequency_count = Counter(responses)\n",
    "\n",
    "# Create a table to display the frequencies\n",
    "table_header = [\"Response\", \"Frequency\"]\n",
    "table_rows = []\n",
    "\n",
    "for response, frequency in frequency_count.items():\n",
    "    table_rows.append([response, frequency])\n",
    "\n",
    "# Sort the table rows based on the response values (first column)\n",
    "table_rows.sort(key=lambda x: x[0])\n",
    "\n",
    "# Print the table\n",
    "print(\"-----------------------\")\n",
    "print(\"| {:<10} | {:<8} |\".format(table_header[0], table_header[1]))\n",
    "print(\"-----------------------\")\n",
    "for row in table_rows:\n",
    "    print(\"| {:<10} | {:<8} |\".format(row[0], row[1]))\n",
    "print(\"-----------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TTQ3.1_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:146\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:49\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TTQ3.1_1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb Cell 9\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m responses \u001b[39m=\u001b[39m [response \u001b[39mfor\u001b[39;00m response \u001b[39min\u001b[39;00m df[\u001b[39m'\u001b[39m\u001b[39mTTQ3.1_1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mTTQ3.1_2\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mTTQ3.1_3\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m response \u001b[39m==\u001b[39m response]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m frequency_count \u001b[39m=\u001b[39m Counter(responses)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m table_header \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mResponse\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFrequency\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TTQ3.1_1'"
     ]
    }
   ],
   "source": [
    "responses = [response for response in df['TTQ3.1_1'] + df['TTQ3.1_2'] + df['TTQ3.1_3'] if response == response]\n",
    "\n",
    "frequency_count = Counter(responses)\n",
    "\n",
    "table_header = ['Response', 'Frequency']\n",
    "table_rows = []\n",
    "\n",
    "for response, frequency in frequency_count.items():\n",
    "    table_rows.append([response, frequency])\n",
    "\n",
    "table_rows.sort(key=lambda x: x[0])\n",
    "\n",
    "# Print the table\n",
    "print(\"-----------------------\")\n",
    "print(\"| {:<10} | {:<8} |\".format(table_header[0], table_header[1]))\n",
    "print(\"-----------------------\")\n",
    "for row in table_rows:\n",
    "    print(\"| {:<10} | {:<8} |\".format(row[0], row[1]))\n",
    "print(\"-----------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TTQ3.1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response is 142, frequency is 6.0\n",
      "{nan: 1, nan: 1, nan: 1, 8.0: 4, 7.0: 7, 5.0: 4, nan: 1, 97.0: 14, nan: 1, nan: 1, nan: 1, 3.0: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, 1.0: 3, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, 4.0: 2, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, 2.0: 8, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, 6.0: 5, nan: 1, 99.0: 4, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, 9.0: 3, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1}\n",
      "freq_Q1       Q1   Q2  Q3\n",
      "NaN  NaN  NaN NaN\n",
      "NaN  NaN  NaN NaN\n",
      "NaN  NaN  NaN NaN\n",
      "8.0  4.0  1.0 NaN\n",
      "7.0  7.0  NaN NaN\n",
      "                                                    CGI1  CGI2_r1  CGI2_r10  \\\n",
      "0                                             White Claw      2.0       1.0   \n",
      "1                                             White claw      1.0       1.0   \n",
      "2                                                  Mikes      2.0       1.0   \n",
      "3                                             topo chico      2.0       1.0   \n",
      "4                                                  Truly      2.0       3.0   \n",
      "...                                                  ...      ...       ...   \n",
      "139                                            Whiteclaw      1.0       2.0   \n",
      "140                                         haed seltzer      1.0       2.0   \n",
      "141                                                Truly      3.0       4.0   \n",
      "142                                               Corona      2.0       2.0   \n",
      "Total  White ClawWhite clawMikestopo chicoTrulyTrulyW...    280.0     316.0   \n",
      "\n",
      "       CGI2_r2  CGI2_r3  CGI2_r4  CGI2_r5  CGI2_r6  CGI2_r7  CGI2_r8  ...  \\\n",
      "0          2.0      3.0      3.0      3.0      5.0      5.0      3.0  ...   \n",
      "1          2.0      4.0      3.0      5.0      5.0      5.0      5.0  ...   \n",
      "2          5.0      2.0      2.0      3.0      5.0      3.0      4.0  ...   \n",
      "3          2.0      1.0      4.0      2.0      2.0      5.0      2.0  ...   \n",
      "4          2.0      2.0      2.0      3.0      2.0      2.0      3.0  ...   \n",
      "...        ...      ...      ...      ...      ...      ...      ...  ...   \n",
      "139        1.0      1.0      2.0      3.0      4.0      4.0      3.0  ...   \n",
      "140        1.0      1.0      1.0      1.0      2.0      2.0      1.0  ...   \n",
      "141        2.0      2.0      4.0      5.0      4.0      5.0      4.0  ...   \n",
      "142        2.0      1.0      1.0      4.0      5.0      4.0      5.0  ...   \n",
      "Total    284.0    292.0    335.0    445.0    469.0    454.0    466.0  ...   \n",
      "\n",
      "       TTQ9_9.16  TTQ9_9.2 TTQ9_9.3  TTQ9_9.4 TTQ9_9.5  TTQ9_9.6  TTQ9_9.7  \\\n",
      "0            NaN       0.0      NaN       NaN      0.0       NaN       NaN   \n",
      "1            0.0       0.0      NaN       0.0      NaN       NaN       NaN   \n",
      "2            NaN       NaN      0.0       0.0      NaN       NaN       0.0   \n",
      "3            NaN       0.0      NaN       NaN      0.0       NaN       0.0   \n",
      "4            NaN       NaN      NaN       1.0      0.0       0.0       NaN   \n",
      "...          ...       ...      ...       ...      ...       ...       ...   \n",
      "139          NaN       NaN      0.0       NaN      NaN       0.0       NaN   \n",
      "140          0.0       0.0      NaN       NaN      NaN       0.0       NaN   \n",
      "141          NaN       0.0      NaN       0.0      0.0       NaN       0.0   \n",
      "142          NaN       NaN      NaN       0.0      NaN       0.0       NaN   \n",
      "Total        2.0       3.0      2.0       7.0      1.0       5.0       3.0   \n",
      "\n",
      "       TTQ9_9.8  TTQ9_9.9  sys_RespNum  \n",
      "0           0.0       NaN          3.0  \n",
      "1           NaN       1.0          4.0  \n",
      "2           0.0       NaN          5.0  \n",
      "3           NaN       NaN          6.0  \n",
      "4           NaN       0.0          7.0  \n",
      "...         ...       ...          ...  \n",
      "139         NaN       NaN        190.0  \n",
      "140         NaN       NaN        191.0  \n",
      "141         NaN       NaN        192.0  \n",
      "142         0.0       NaN        193.0  \n",
      "Total       1.0       6.0      14668.0  \n",
      "\n",
      "[144 rows x 902 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "# Q1 = [1, 1, 4, 2, 3]\n",
    "# Q2 = [2, 3, 5, 5, 6]\n",
    "# Q3 = [1, 2, 7, 2, 6]\n",
    "\n",
    "# Initialize empty dictionaries for frequencies\n",
    "freq_Q1 = {}\n",
    "freq_Q2 = {}\n",
    "freq_Q3 = {}\n",
    "\n",
    "for response, frequency in df['TTQ3.1_1'].items():\n",
    "    table_rows.append([response, frequency])\n",
    "print(f'response is {response}, frequency is {frequency}')\n",
    "\n",
    "# Count frequencies for Q1\n",
    "for response in df['TTQ3.1_1']:\n",
    "    freq_Q1[response] = freq_Q1.get(response, 0) + 1\n",
    "\n",
    "print(freq_Q1)\n",
    "\n",
    "# Count frequencies for Q2\n",
    "for response in df['TTQ3.1_2']:\n",
    "    freq_Q2[response] = freq_Q2.get(response, 0) + 1\n",
    "\n",
    "# Count frequencies for Q3\n",
    "for response in df['TTQ3.1_3']:\n",
    "    freq_Q3[response] = freq_Q3.get(response, 0) + 1\n",
    "\n",
    "# Combine frequencies into a table\n",
    "table = {\"Q1\": freq_Q1, \"Q2\": freq_Q2, \"Q3\": freq_Q3}\n",
    "\n",
    "# Create a DataFrame from the table\n",
    "df2 = pd.DataFrame(table)\n",
    "\n",
    "print(f'freq_Q1', df2.head())\n",
    "\n",
    "# Transpose the DataFrame\n",
    "df2 = df.transpose()\n",
    "\n",
    "# Sort columns in ascending order\n",
    "df2 = df.sort_index(axis=1)\n",
    "\n",
    "# Add a total row\n",
    "df2.loc['Total'] = df.sum()\n",
    "\n",
    "# Print the transposed table with total row\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: TTQ3.1_1\n",
      "97.0    14\n",
      "2.0      8\n",
      "7.0      7\n",
      "6.0      5\n",
      "8.0      4\n",
      "5.0      4\n",
      "99.0     4\n",
      "1.0      3\n",
      "9.0      3\n",
      "4.0      2\n",
      "3.0      1\n",
      "Name: TTQ3.1_1, dtype: int64\n",
      "-------------------\n",
      "Variable: TTQ3.1_2\n",
      "6.0    3\n",
      "2.0    1\n",
      "8.0    1\n",
      "5.0    1\n",
      "Name: TTQ3.1_2, dtype: int64\n",
      "-------------------\n",
      "Variable: TTQ3.1_3\n",
      "Series([], Name: TTQ3.1_3, dtype: int64)\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "variable_names = ['TTQ3.1_1', 'TTQ3.1_2','TTQ3.1_3']\n",
    "\n",
    "for variable in variable_names:\n",
    "    frequencies = df[variable].value_counts()\n",
    "    print(f\"Variable: {variable}\")\n",
    "    print(frequencies)\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     NaN\n",
      "1     NaN\n",
      "2     NaN\n",
      "3     NaN\n",
      "4     NaN\n",
      "       ..\n",
      "138   NaN\n",
      "139   NaN\n",
      "140   NaN\n",
      "141   NaN\n",
      "142   NaN\n",
      "Length: 143, dtype: float64\n",
      "-----------------------\n",
      "| Response   | Frequency |\n",
      "-----------------------\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "| nan        | 1        |\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Define the data\n",
    "Q1 = df['TTQ3.1_1']\n",
    "Q2 = df['TTQ3.1_2']\n",
    "Q3 = df['TTQ3.1_3']\n",
    "\n",
    "# Combine the responses into a single list\n",
    "responses = Q1 + Q2 + Q3\n",
    "print(responses)\n",
    "# Count the frequencies of each response\n",
    "frequency_count = Counter(responses)\n",
    "\n",
    "# Create a table to display the frequencies\n",
    "table_header = [\"Response\", \"Frequency\"]\n",
    "table_rows = []\n",
    "\n",
    "for response, frequency in frequency_count.items():\n",
    "    table_rows.append([response, frequency])\n",
    "\n",
    "# Sort the table rows based on the response values (first column)\n",
    "table_rows.sort(key=lambda x: x[0])\n",
    "\n",
    "# Print the table\n",
    "print(\"-----------------------\")\n",
    "print(\"| {:<10} | {:<8} |\".format(table_header[0], table_header[1]))\n",
    "print(\"-----------------------\")\n",
    "for row in table_rows:\n",
    "    print(\"| {:<10} | {:<8} |\".format(row[0], row[1]))\n",
    "print(\"-----------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sys_RespNum</th>\n",
       "      <th>RespondentIDNumber</th>\n",
       "      <th>RotationNumb</th>\n",
       "      <th>ContactInfo_first</th>\n",
       "      <th>ContactInfo_last</th>\n",
       "      <th>ContactInfo_email</th>\n",
       "      <th>ContactInfo_Phone</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>...</th>\n",
       "      <th>TTQ10Third_2</th>\n",
       "      <th>TTQ10Third_3</th>\n",
       "      <th>TTQ10Third_4</th>\n",
       "      <th>DQ1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>QtaGender</th>\n",
       "      <th>QtaAge</th>\n",
       "      <th>QtaEthnic</th>\n",
       "      <th>CombinedVariable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Crystal</td>\n",
       "      <td>Mills</td>\n",
       "      <td>Crystal_clear25@hotmail.com</td>\n",
       "      <td>409-338-7258</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nannannan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>Palomo</td>\n",
       "      <td>Jonpalomo@gmail.com</td>\n",
       "      <td>8323615539</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nannannan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Catherine</td>\n",
       "      <td>Josey</td>\n",
       "      <td>Josey1love@aol.com</td>\n",
       "      <td>2812359625</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nannannan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>ivan</td>\n",
       "      <td>galvan</td>\n",
       "      <td>ivangal66@yahoo.com</td>\n",
       "      <td>2812221429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0nannan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Natasha</td>\n",
       "      <td>Thornton</td>\n",
       "      <td>Narensthornton@gmail.com</td>\n",
       "      <td>510-421-9043</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0nannan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 903 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sys_RespNum RespondentIDNumber  RotationNumb ContactInfo_first  \\\n",
       "0          3.0                  8           8.0           Crystal   \n",
       "1          4.0                  2           2.0          Jonathan   \n",
       "2          5.0                  5           5.0         Catherine   \n",
       "3          6.0                 12          12.0              ivan   \n",
       "4          7.0                  3           3.0           Natasha   \n",
       "\n",
       "  ContactInfo_last            ContactInfo_email ContactInfo_Phone   S1   S2  \\\n",
       "0            Mills  Crystal_clear25@hotmail.com      409-338-7258  2.0  3.0   \n",
       "1           Palomo          Jonpalomo@gmail.com        8323615539  1.0  3.0   \n",
       "2            Josey           Josey1love@aol.com        2812359625  2.0  4.0   \n",
       "3           galvan          ivangal66@yahoo.com        2812221429  1.0  3.0   \n",
       "4         Thornton     Narensthornton@gmail.com      510-421-9043  2.0  4.0   \n",
       "\n",
       "    S3  ...  TTQ10Third_2  TTQ10Third_3  TTQ10Third_4  DQ1   D2   D3  \\\n",
       "0  1.0  ...           NaN           NaN           NaN  3.0  0.0  4.0   \n",
       "1  3.0  ...           NaN           NaN           NaN  1.0  1.0  4.0   \n",
       "2  1.0  ...           NaN           NaN           NaN  2.0  1.0  6.0   \n",
       "3  3.0  ...          12.0           NaN           NaN  4.0  0.0  3.0   \n",
       "4  4.0  ...           NaN           NaN           NaN  1.0  0.0  3.0   \n",
       "\n",
       "   QtaGender  QtaAge  QtaEthnic  CombinedVariable  \n",
       "0        2.0     2.0        1.0         nannannan  \n",
       "1        1.0     2.0        3.0         nannannan  \n",
       "2        2.0     3.0        1.0         nannannan  \n",
       "3        1.0     2.0        3.0         8.0nannan  \n",
       "4        2.0     3.0        4.0         7.0nannan  \n",
       "\n",
       "[5 rows x 903 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan,  8.,  7.,  5., nan, 97., nan, nan, nan,  3., nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan,  1., nan, nan, nan,\n",
       "       nan, nan, nan, 97., nan, nan, nan,  4., 97., nan, nan, nan, nan,\n",
       "        7., nan, nan, nan, nan, 97.,  2., nan, nan, nan, nan, nan, 97.,\n",
       "       nan,  1., nan, nan, nan, nan, 97., 97.,  8., nan, 97., 97., nan,\n",
       "       nan,  5.,  6., 97.,  6., nan, 99., nan, 97., nan, nan, nan, nan,\n",
       "        9.,  1.,  6.,  7.,  2., 99.,  5., nan,  2.,  2., nan, nan, nan,\n",
       "       nan, nan,  2., nan,  7., nan,  2.,  8., nan,  7., nan, nan, nan,\n",
       "        2., 97.,  8., nan,  7., nan, nan, 97., nan,  5., nan, nan, nan,\n",
       "       nan,  6., nan,  4., nan, 99.,  2., nan,  7., nan, 97., nan, nan,\n",
       "       nan, 99., nan, nan, nan, nan, nan, nan, nan,  9., nan,  9.,  6.,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan,  2., nan, nan, nan,  6., nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan,  6., nan, nan, nan, nan,  6., nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan,  8., nan,  5., nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyreadstat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "# # Read the SPSS database\n",
    "# data_path = 'path/to/your/database.sav'\n",
    "# df, meta = pyreadstat.read_sav(data_path)\n",
    "\n",
    "# Define the data\n",
    "# Q1 = df['TTQ3.1_1']\n",
    "# Q2 = df['TTQ3.1_2']\n",
    "# Q3 = df['TTQ3.1_3']\n",
    "# Combine two variables into a new variable\n",
    "variable1 = 'TTQ3.1_1'  # Replace with your variable name\n",
    "variable2 = 'TTQ3.1_2'  # Replace with your variable name\n",
    "variable3 = 'TTQ3.1_3'  # Replace with your variable name\n",
    "\n",
    "# new_variable_name = 'CombinedVariable'  # Replace with your desired new variable name\n",
    "\n",
    "new_variable = np.concatenate([df[variable1], df[variable2], df[variable3]])\n",
    "\n",
    "new_variable\n",
    "# Save the modified database\n",
    "# output_path = 'path/to/save/combined_database.sav'  # Replace with your desired output path\n",
    "# pyreadstat.write_sav(df, meta, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb Cell 16\u001b[0m in \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m new_frequencies \u001b[39m=\u001b[39m frequencies[np\u001b[39m.\u001b[39mlogical_not(pd\u001b[39m.\u001b[39misna(frequencies))]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# print(f\"Variable: {variable}\")\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m new_frequencies\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "# frequencies = df[new_variable].value_counts()\n",
    "frequencies = collections.Counter(new_variable)\n",
    "new_frequencies = frequencies[np.logical_not(pd.isna(frequencies))]\n",
    "# print(f\"Variable: {variable}\")\n",
    "\n",
    "for key, value in new_frequencies.items():\n",
    "    print(f'{key}: {value}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for Taste Test Most/Least slides\n",
    "#### Concat several variables, get frequencies and percentages for the resulting joined variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: 3 (5%)\n",
      "2.0: 9 (15%)\n",
      "3.0: 1 (2%)\n",
      "4.0: 2 (3%)\n",
      "5.0: 5 (8%)\n",
      "6.0: 8 (13%)\n",
      "7.0: 7 (11%)\n",
      "8.0: 5 (8%)\n",
      "9.0: 3 (5%)\n",
      "97.0: 14 (23%)\n",
      "99.0: 4 (7%)\n",
      "Total counts: 61\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "# from collections import Counter\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "# Define the data\n",
    "Q1 = df['TTQ3.1_1']\n",
    "Q2 = df['TTQ3.1_2']\n",
    "Q3 = df['TTQ3.1_3']\n",
    "\n",
    "# Combine the responses into a single list\n",
    "responses = pd.concat([Q1, Q2, Q3], axis=0, ignore_index=True).dropna(axis=0)\n",
    "\n",
    "# count responses by variable value\n",
    "value_counts = responses.value_counts().sort_index()\n",
    "# print(value_counts)\n",
    "\n",
    "# Calculate the percentages\n",
    "percentages = (value_counts / value_counts.sum()) * 100\n",
    "\n",
    "# Print the value counts and percentages\n",
    "for value, count in value_counts.items():\n",
    "    percentage = percentages[value]\n",
    "    print(f\"{value}: {count} ({percentage:.0f}%)\")\n",
    "\n",
    "# get total number of counts\n",
    "total_counts = value_counts.sum()\n",
    "print(f'Total counts: {total_counts}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate tuple (not \"str\") to tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb Cell 19\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m df_list \u001b[39m=\u001b[39m()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m variable \u001b[39min\u001b[39;00m variable_list:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     df_list \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdf[\u001b[39m\u001b[39m{\u001b[39;00mvariable\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m df_list\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate tuple (not \"str\") to tuple"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "# from collections import Counter\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "variable_list = ['TTQ3.1_1','TTQ3.1_2','TTQ3.1_3']\n",
    "df_list =()\n",
    "\n",
    "for variable in variable_list:\n",
    "    df_list += f'df[{variable}]'\n",
    "\n",
    "df_list     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"df['TTQ3.1_1']\", \"df['TTQ3.1_2']\", \"df['TTQ3.1_3']\"]\n"
     ]
    }
   ],
   "source": [
    "variable_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "new_list = []\n",
    "\n",
    "for variable in variable_list:\n",
    "    new_list.append(\"df['\" + variable + \"']\")\n",
    "\n",
    "print(new_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"df['TTQ3.1_1']\", \"df['TTQ3.1_2']\", \"df['TTQ3.1_3']\"]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Q1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(new_list)\n\u001b[1;32m     15\u001b[0m \u001b[39m# Combine the responses into a single list\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m responses \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([Q1, Q2, Q3], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mdropna(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Q1' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "# from collections import Counter\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "variable_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "new_list = []\n",
    "\n",
    "for variable in variable_list:\n",
    "    new_list.append(\"df['\" + variable + \"']\")\n",
    "\n",
    "print(new_list)\n",
    "\n",
    "# Combine the responses into a single list\n",
    "responses = pd.concat([Q1, Q2, Q3], axis=0, ignore_index=True).dropna(axis=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"df['TTQ3.1_1']\", \"df['TTQ3.1_2']\", \"df['TTQ3.1_3']\"]\n"
     ]
    }
   ],
   "source": [
    "variable_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "new_list = []\n",
    "\n",
    "for variable in variable_list:\n",
    "    new_list.append(\"df['\" + variable + \"']\")\n",
    "\n",
    "# Remove double quotes from the strings in new_list\n",
    "new_list = [item.replace(\"\", '') for item in new_list]\n",
    "\n",
    "print(new_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"[df['TTQ3.1_1']]\", \"[df['TTQ3.1_2']]\", \"[df['TTQ3.1_3']]\"]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb Cell 23\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb#X31sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(new_list)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb#X31sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Combine the responses into a single list\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/patescalona/Projects/Coding/python/taste_test_scripts/taste_test_scripts.ipynb#X31sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m responses \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(new_list, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mdropna(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/reshape/concat.py:369\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobjs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat\u001b[39m(\n\u001b[1;32m    149\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m     copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    159\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m    160\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[39m    1   3   4\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    370\u001b[0m         objs,\n\u001b[1;32m    371\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    372\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    373\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    374\u001b[0m         keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    375\u001b[0m         levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    376\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    377\u001b[0m         verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    378\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    379\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    380\u001b[0m     )\n\u001b[1;32m    382\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/reshape/concat.py:459\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[1;32m    455\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    456\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot concatenate object of type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(obj)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39monly Series and DataFrame objs are valid\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    458\u001b[0m         )\n\u001b[0;32m--> 459\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    461\u001b[0m     ndims\u001b[39m.\u001b[39madd(obj\u001b[39m.\u001b[39mndim)\n\u001b[1;32m    463\u001b[0m \u001b[39m# get the sample\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[39m# want the highest ndim that we have, and must be non-empty\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[39m# unless all objs are empty\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "variable_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "new_list = []\n",
    "\n",
    "for variable in variable_list:\n",
    "    new_list.append(\"df['\" + variable + \"']\")\n",
    "\n",
    "# Add square brackets to each string in new_list\n",
    "new_list = ['[' + item + ']' for item in new_list]\n",
    "\n",
    "print(new_list)\n",
    "\n",
    "# Combine the responses into a single list\n",
    "responses = pd.concat(new_list, axis=0, ignore_index=True).dropna(axis=0)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatGPT generated code\n",
    "#### Write a python script that automatically generates a sequential variable name and assigns a value to it from a list of provided values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var1 = 10\n",
      "var2 = 20\n",
      "var3 = 30\n",
      "var4 = 40\n",
      "var5 = 50\n"
     ]
    }
   ],
   "source": [
    "def generate_variable_names(values):\n",
    "    variable_names = []\n",
    "    for i, value in enumerate(values):\n",
    "        variable_name = f'var{i+1}'  # Generate variable name\n",
    "        globals()[variable_name] = value  # Assign value to variable\n",
    "        variable_names.append(variable_name)\n",
    "    return variable_names\n",
    "\n",
    "# Example usage\n",
    "values_list = [10, 20, 30, 40, 50]\n",
    "result = generate_variable_names(values_list)\n",
    "\n",
    "# Print variable names and their corresponding values\n",
    "for variable_name in result:\n",
    "    print(f'{variable_name} = {globals()[variable_name]}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This works but generated var# series is called outside of scope and says not defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = ['var1', 'var2', 'var3']\n",
      "var1 = TTQ3.1_1\n",
      "var2 = TTQ3.1_2\n",
      "var3 = TTQ3.1_3\n",
      "merged_varible = \n",
      "3       8.0\n",
      "4       7.0\n",
      "5       5.0\n",
      "7      97.0\n",
      "11      3.0\n",
      "       ... \n",
      "227     6.0\n",
      "251     6.0\n",
      "256     6.0\n",
      "282     8.0\n",
      "284     5.0\n",
      "Length: 61, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "merged_variable = pd.DataFrame()\n",
    "\n",
    "def generate_variable_names(values):\n",
    "    variable_names = []\n",
    "    for i, value in enumerate(values):\n",
    "        variable_name = f'var{i+1}'  # Generate variable name\n",
    "        globals()[variable_name] = value  # Assign value to variable\n",
    "        variable_names.append(variable_name)\n",
    "    return variable_names\n",
    "\n",
    "# Example usage\n",
    "values_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "result = generate_variable_names(values_list)\n",
    "print(f'result = {result}')\n",
    "\n",
    "# Print variable names and their corresponding values\n",
    "for variable_name in result:\n",
    "    print(f'{variable_name} = {globals()[variable_name]}')\n",
    "\n",
    "\n",
    "\n",
    "merged_variable = pd.concat([df[f'{var1}'], df[var2], df[var3]], axis=0, ignore_index=True).dropna(axis=0)\n",
    "print(f'merged_varible = \\n{merged_variable}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = ['df[var1],', 'df[var2],', 'df[var3],']\n",
      "df[var1], = TTQ3.1_1\n",
      "df[var2], = TTQ3.1_2\n",
      "df[var3], = TTQ3.1_3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mvariable_name\u001b[39m}\u001b[39;00m\u001b[39m = \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mglobals\u001b[39m()[variable_name]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39m# merged_variable = pd.concat([df[var1], df[var2], df[var3]], axis=0, ignore_index=True).dropna(axis=0)\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m merged_variable \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat([result], axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, ignore_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mdropna(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[39mprint\u001b[39m(merged_variable)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/reshape/concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    370\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    373\u001b[0m     objs,\n\u001b[1;32m    374\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    375\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    376\u001b[0m     join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    377\u001b[0m     keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    378\u001b[0m     levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    379\u001b[0m     names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    380\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    381\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    382\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    383\u001b[0m )\n\u001b[1;32m    385\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/reshape/concat.py:462\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[1;32m    458\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    459\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot concatenate object of type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(obj)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    460\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39monly Series and DataFrame objs are valid\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m         )\n\u001b[0;32m--> 462\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    464\u001b[0m     ndims\u001b[39m.\u001b[39madd(obj\u001b[39m.\u001b[39mndim)\n\u001b[1;32m    466\u001b[0m \u001b[39m# get the sample\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[39m# want the highest ndim that we have, and must be non-empty\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m# unless all objs are empty\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "merged_variable = pd.DataFrame()\n",
    "\n",
    "def generate_variable_names(values):\n",
    "    variable_names = []\n",
    "    concated_variables = pd.DataFrame()\n",
    "    for i, value in enumerate(values):\n",
    "        variable_name = f'df[var{i+1}],'  # Generate variable name\n",
    "        globals()[variable_name] = value  # Assign value to variable\n",
    "        variable_names.append(variable_name)\n",
    "        concated_variables = pd.concat([concated_variables, variable_name])\n",
    "    return concated_variables\n",
    "\n",
    "# Example usage\n",
    "values_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "result = generate_variable_names(values_list)\n",
    "print(f'result = {result}')\n",
    "\n",
    "# Print variable names and their corresponding values\n",
    "for variable_name in result:\n",
    "    print(f'{variable_name} = {globals()[variable_name]}')\n",
    "\n",
    "# merged_variable = pd.concat([df[var1], df[var2], df[var3]], axis=0, ignore_index=True).dropna(axis=0)\n",
    "merged_variable = pd.concat([result], axis=0, ignore_index=True).dropna(axis=0)\n",
    "print(merged_variable)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix undefined var# series error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n\u001b[1;32m     22\u001b[0m variable_list \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mTTQ3.1_1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTTQ3.1_2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTTQ3.1_3\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 23\u001b[0m result \u001b[39m=\u001b[39m concat_variables(variable_list)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mresult = \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[54], line 17\u001b[0m, in \u001b[0;36mconcat_variables\u001b[0;34m(vars_list)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[39mglobals\u001b[39m()[variable_name] \u001b[39m=\u001b[39m value  \u001b[39m# Assign value to variable\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     variable_names\u001b[39m.\u001b[39mappend(variable_name)\n\u001b[0;32m---> 17\u001b[0m     \u001b[39mglobals\u001b[39;49m()[concated_variable_values] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([concated_variable_values, df[value] ])\n\u001b[1;32m     18\u001b[0m \u001b[39mreturn\u001b[39;00m concated_variable_values\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'DataFrame'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat\n",
    "\n",
    "df, meta = pyreadstat.read_sav('../../SPSS-Python/spss-datasets/Taste_Test_Data_File.sav')\n",
    "\n",
    "\n",
    "# Function to read variable list and concatenate all into one dataframe\n",
    "def concat_variables(vars_list):\n",
    "    #create dataframe to store concated values\n",
    "    concated_variable_values = pd.DataFrame()\n",
    "    variable_names = []\n",
    "\n",
    "    for i, value in enumerate(vars_list):\n",
    "        variable_name = f'var{i+1}'  # Generate variable name\n",
    "        globals()[variable_name] = value  # Assign value to variable\n",
    "        variable_names.append(variable_name)\n",
    "        globals()[concated_variable_values] = pd.concat([concated_variable_values, df[value] ])\n",
    "    return concated_variable_values\n",
    "\n",
    "\n",
    "# Example usage\n",
    "variable_list = ['TTQ3.1_1', 'TTQ3.1_2', 'TTQ3.1_3']\n",
    "result = concat_variables(variable_list)\n",
    "print(f'result = {result}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
